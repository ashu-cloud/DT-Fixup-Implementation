{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EimJmJ9uJYso"
      },
      "source": [
        "Import dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3uXdLMxMhPpI",
        "outputId": "f5b80591-ece2-40aa-87ef-1362f8f661ac"
      },
      "source": [
        "!pip install datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "import copy\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from tensorflow import keras\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.5 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-86fda589290b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a=torch.ones(2,2)\n",
        "print(a==0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ykrY-AuIIw0",
        "outputId": "973b3809-4d65-4c26-af74-cb290d9d7352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yFi51E-RZMc",
        "outputId": "a8ebac8d-f203-4073-866d-b6bd73f8a322"
      },
      "source": [
        "device = \"cuda\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH_isjzsckOG"
      },
      "source": [
        "en = spacy.load('en')\n",
        "def tokenize_en(sentence):\n",
        "    return [tok.text for tok in en.tokenizer(sentence)]\n",
        "EN_TEXT = Field(tokenize=tokenize_en)\n",
        "SQL_TEXT = Field(tokenize=tokenize_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJtAhoRxJg2U"
      },
      "source": [
        "We work on the spider data-set, convert format into: query -> answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "f7309a1e64bd4518a1833393f17f63bc",
            "c1965d6e524e43d9909eddbda87c6ffa",
            "e73bd1ab14224900871be6200a3d85d3",
            "e14d4486007e40a6827449302b363da5",
            "5ec3103be13a41bb81640dac5ff00d8d",
            "8f476c422214421790b9325bd12a3866"
          ]
        },
        "id": "67BQzXTQJpSM",
        "outputId": "0d95f1a2-e1d8-4a78-e3c9-431cb9f7187a"
      },
      "source": [
        "spider = load_dataset('spider')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7309a1e64bd4518a1833393f17f63bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1965d6e524e43d9909eddbda87c6ffa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/837 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset spider/spider (download: 95.12 MiB, generated: 5.17 MiB, post-processed: Unknown size, total: 100.29 MiB) to /root/.cache/huggingface/datasets/spider/spider/1.0.0/79778ebea87c59b19411f1eb3eda317e9dd5f7788a556d837ef25c3ae6e5e8b7...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73bd1ab14224900871be6200a3d85d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/99.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e14d4486007e40a6827449302b363da5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ec3103be13a41bb81640dac5ff00d8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset spider downloaded and prepared to /root/.cache/huggingface/datasets/spider/spider/1.0.0/79778ebea87c59b19411f1eb3eda317e9dd5f7788a556d837ef25c3ae6e5e8b7. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f476c422214421790b9325bd12a3866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJMlyhvVSL80",
        "outputId": "ac41c09e-dfc1-4342-a035-1cc5cb000987"
      },
      "source": [
        "train_set = spider.get('train')\n",
        "tokenize_en(train_set[1]['query'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SELECT',\n",
              " 'name',\n",
              " ',',\n",
              " ' ',\n",
              " 'born_state',\n",
              " ',',\n",
              " ' ',\n",
              " 'age',\n",
              " 'FROM',\n",
              " 'head',\n",
              " 'ORDER',\n",
              " 'BY',\n",
              " 'age']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm-5v6Tyna_Y"
      },
      "source": [
        "raw_data = {'Text' : [line for line in train_set['question']], 'SQL': [line for line in train_set['query']]}\n",
        "df = pd.DataFrame(raw_data, columns=[\"Text\", \"SQL\"])\n",
        "# remove very long sentences and sentences where translations are \n",
        "# not of roughly equal length\n",
        "df['text_len'] = df['Text'].str.count(' ')\n",
        "df['sql_len'] = df['SQL'].str.count(' ')\n",
        "#removing very long queries and questions \n",
        "df = df.query('sql_len < 80 & text_len < 80')\n",
        "df = df.query('sql_len < text_len * 1.5 & sql_len * 1.5 > text_len')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nWzkJF2KoA6J",
        "outputId": "c3326599-ae8a-42bb-ffce-00e3cb8b045b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>SQL</th>\n",
              "      <th>text_len</th>\n",
              "      <th>sql_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many heads of the departments are older th...</td>\n",
              "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>List the name, born state and age of the heads...</td>\n",
              "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>List the creation year, name and budget of eac...</td>\n",
              "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What are the names of the states where at leas...</td>\n",
              "      <td>SELECT born_state FROM head GROUP BY born_stat...</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Show the name and number of employees for the ...</td>\n",
              "      <td>SELECT T1.name ,  T1.num_employees FROM depart...</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6986</th>\n",
              "      <td>What is the title and director for the movie w...</td>\n",
              "      <td>SELECT title ,  director FROM movie WHERE YEAR...</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6987</th>\n",
              "      <td>Return the title and director of the movie rel...</td>\n",
              "      <td>SELECT title ,  director FROM movie WHERE YEAR...</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990</th>\n",
              "      <td>Show all director names who have a movie in th...</td>\n",
              "      <td>SELECT director FROM movie WHERE YEAR  =  1999...</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6992</th>\n",
              "      <td>What is the average, maximum, and minimum budg...</td>\n",
              "      <td>SELECT avg(budget_million) ,  max(budget_milli...</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6993</th>\n",
              "      <td>Return the average, maximum, and minimum budge...</td>\n",
              "      <td>SELECT avg(budget_million) ,  max(budget_milli...</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3174 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ... sql_len\n",
              "0     How many heads of the departments are older th...  ...       9\n",
              "1     List the name, born state and age of the heads...  ...      12\n",
              "2     List the creation year, name and budget of eac...  ...       9\n",
              "7     What are the names of the states where at leas...  ...      12\n",
              "9     Show the name and number of employees for the ...  ...      24\n",
              "...                                                 ...  ...     ...\n",
              "6986  What is the title and director for the movie w...  ...      18\n",
              "6987  Return the title and director of the movie rel...  ...      18\n",
              "6990  Show all director names who have a movie in th...  ...      15\n",
              "6992  What is the average, maximum, and minimum budg...  ...      15\n",
              "6993  Return the average, maximum, and minimum budge...  ...      15\n",
              "\n",
              "[3174 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJio1bTaogSI"
      },
      "source": [
        "# create train and validation set \n",
        "train, val = train_test_split(df, test_size=0.1)\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "val.to_csv(\"val.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IystOMPomjM"
      },
      "source": [
        "# associate the text in the 'Text' column with the EN_TEXT field, and 'SQL' with SQL_TEXT\n",
        "data_fields = [('Text', EN_TEXT), ('SQL', SQL_TEXT)]\n",
        "train, val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-0jLLh6p1FO"
      },
      "source": [
        "SQL_TEXT.build_vocab(train, val)\n",
        "EN_TEXT.build_vocab(train, val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K48YhYbzp7HV",
        "outputId": "cb223fb9-4afb-4bab-d17a-57b841fa59cf"
      },
      "source": [
        "#tokens for some example words in the SQL queries and the Text data\n",
        "print(SQL_TEXT.vocab.stoi['SELECT'])\n",
        "print(EN_TEXT.vocab.stoi['What'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ORPDD1qrwv"
      },
      "source": [
        "train_iter = BucketIterator(train, batch_size=20, sort_key=lambda x: len(x.SQL), shuffle=True)\n",
        "val_iter = BucketIterator(val, batch_size=20, sort_key=lambda x: len(x.SQL), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnJDD7Wsq1eD",
        "outputId": "7dcf4d1e-204e-4aaa-8844-be6ab21f4ae8"
      },
      "source": [
        "#an example of a batch\n",
        "batch = next(iter(train_iter))\n",
        "print(batch.SQL)\n",
        "print(batch.Text)\n",
        "#all the 1s are paddings\n",
        "\n",
        "#FINDING MAX INPUT NORM\n",
        "max_inp_norm = -1\n",
        "for i, batch in enumerate(train_iter):\n",
        "    for j in batch.Text:\n",
        "        max_inp_norm = max(max_inp_norm, torch.linalg.norm(j.to(torch.float)))\n",
        "\n",
        "print(max_inp_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
            "            4,    4,    4,    4,    4,    4,    4,    4],\n",
            "        [  27,  972, 1055,   27,   24,   15, 1202, 2507,  698,   15,   27,  754,\n",
            "           50,   58,  337,  612, 1957,  577, 2150,  966],\n",
            "        [ 135,    3,    9,   79,    3,   11,    3,    9,    3,   11,  604,    5,\n",
            "          135,    3,    3,    9,    9,    9,    9,    3],\n",
            "        [   3,  181,    2,    3,  393,   12,  324,    2,  178,   12,    3,    9,\n",
            "            5,  124,  417,    2,    2,    2,    2,  398],\n",
            "        [ 143,    6,  345, 2167,    6,    5,   17, 2521,    6,    5,  339,    2,\n",
            "            3,    6,    6, 1669, 1958, 1803, 2145,    6],\n",
            "        [   6,  385,    3,    1,  749,    3,   25,    9,  364,    3,   17,  756,\n",
            "           74,  167,  448,    3,    9,    3,    3,  966],\n",
            "        [  63,    2,  395,    1,   64,  115,   22,    2,    2,  346,   25,    5,\n",
            "            1,   32,    2,   92,    2,  985,  133,   38],\n",
            "        [   2,    7,   14,    1,   83,    6,   77, 1662,   18,    6,   22,    9,\n",
            "            1,   31,   30,   17, 1010,    1,   17,   10],\n",
            "        [  18,    2,    8,    1,   28,   58,   17,    9,    2, 1867,  994,    2,\n",
            "            1,   11,    2,   25,    3,    1,  144,   41],\n",
            "        [   2,   10, 1055,    1,  229,   38,   26,    2, 2207,    2,   17,  131,\n",
            "            1,    4,   44,   22, 1011,    1,   22, 1911],\n",
            "        [ 287,  934,    1,    1,    1,   10,   23, 1688,   49,   18,   26,    3,\n",
            "            1,  167,   39,  301,   14,    1,  519,   10],\n",
            "        [   1,  821,    1,    1,    1,   41,  601,    3,    4,    2,   23,   59,\n",
            "            1,    3, 2170,   17,    8,    1,   17,    1],\n",
            "        [   1,   10,    1,    1,    1, 1459,    2,  114,  698,   11,  374,   16,\n",
            "            1, 1049,    2,   26, 1010,    1,  128,    1],\n",
            "        [   1,    1,    1,    1,    1,   10,    7,   17,    3,    4,    7,    8,\n",
            "            1,    5,   18,   23,    1,    1,   23,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    2,   25,  178, 1218,  461,  131,\n",
            "            1,    1,    2, 1694,    1,    1, 1284,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,  718,   22,    6,    5,    6,   14,\n",
            "            1,    1,   75,    2,    1,    1,    2,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    6,   76,  364,    3,  929,    8,\n",
            "            1,    1,    1,    7,    1,    1,    7,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,  341,   17,    2,  346,    7,  131,\n",
            "            1,    1,    1,    2,    1,    1,    2,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,   38,   26,   30,    5,   20,    1,\n",
            "            1,    1,    1,  721,    1,    1, 1287,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,   13,   23,    2,    1,   28,    1,\n",
            "            1,    1,    1,    1,    1,    1,   14,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,   41,  213,  564,    1,  932,    1,\n",
            "            1,    1,    1,    1,    1,    1,    8,    1],\n",
            "        [   1,    1,    1,    1,    1,    1, 1591,    2,    1,    1,    7,    1,\n",
            "            1,    1,    1,    1,    1,    1, 2137,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,   13,    7,    1,    1,   20,    1,\n",
            "            1,    1,    1,    1,    1,    1,   19,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    2,    1,    1,   28,    1,\n",
            "            1,    1,    1,    1,    1,    1,   20,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,  188,    1,    1, 1199,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    6,    1,    1,   18,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1, 1743,    1,    1,  161,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    2,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    7,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    2,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   13,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1, 1543,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   13,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
            "tensor([[  27,    7,    7,   21,    7,   67,    7,    7,   23,   28,    7,   75,\n",
            "           90,   21,   54,    7,   27,    7,   49,    7],\n",
            "        [   2,   10,    8,   12,    8,    2,    8,    8,    2,   25,    8,    2,\n",
            "           25,    2,  329,    8,  212,    8,    2,    8],\n",
            "        [  57,    2,    2,    2,    2,   17,    2,    2,   65,  183,    2,   72,\n",
            "           53,   13, 1448,    2, 2087,    2,   13,    2],\n",
            "        [ 504,  125,   92, 2316,   11,    3,   13,   42,   38,   19,   43,    6,\n",
            "          504,    3,   19,   43,  198,   70,    3,  185],\n",
            "        [   3,    3,    6,   88,    3,  275,    3,   15,   92,   31,   11,   93,\n",
            "            8,    2,  697,   11,   43,    6,    2,  200],\n",
            "        [ 339,    2,   11,    5,  209,   35,  109,   11,   16,  401,    3,   65,\n",
            "           47,  113,  192,    3,   13, 2312,  260,   11],\n",
            "        [ 313,  366,   20,    1,   16,  160,  758,   15,   19,  191,    2,  244,\n",
            "            4,   16,   98,   12,   15,    3,    6,   16],\n",
            "        [  22,  130,   12,    1, 1150,  176,   29,  104,  119,  127,   53,   20,\n",
            "            1,   59,   45,  722,  919,   24,    2,  264],\n",
            "        [ 386,   18,  505,    1,  118,    2,   51,    3,   78,    2,  229,   24,\n",
            "            1,   39,  127,   26,   13, 2004,  750,    2],\n",
            "        [   5,  862,   15,    1,  150,  216,   35,  253,   14,   30,   26,   65,\n",
            "            1,   19,  141,   19,    6,    4,  892,  216],\n",
            "        [   1,  850,  148,    1,    6,   37,   43,   15,   60,  401,  480,   38,\n",
            "            1,   48,    4,  355,   52,    1,    2,   18],\n",
            "        [   1,   18,   29,    1,  297, 1284,   13,    6,  106,  191,    9,   15,\n",
            "            1, 1141,   21,   31,   13,    1, 1573, 1452],\n",
            "        [   1,    4,   92,    1,  186,   37,   46,  464,   22,    4,  254,  779,\n",
            "            1,    4,    2,  144,    9,    1,  508,   18],\n",
            "        [   1,    1,    4,    1,    4,    5,   18,  114, 1673,    1,  147,    6,\n",
            "            1,    1,  329,    6,   99,    1,   20,    4],\n",
            "        [   1,    1,    1,    1,    1,    1,  656,   20,    6,    1,   84,   68,\n",
            "            1,    1,  418,    2,   32,    1,    2,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,   18,  183,   78,    1,  455,   29,\n",
            "            1,    1,   11,  117,   29,    1,  179,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    9,  117,   14,    1,  957,   65,\n",
            "            1,    1,    5,  144,   52,    1,   16,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,  707,   56,   60,    1,    6,   38,\n",
            "            1,    1,    1,   92,   13,    1,  112,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    4,    2,  201,    1,  111,    5,\n",
            "            1,    1,    1,    4,    5,    1,  249,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   63,   22,    1,   40,    1,\n",
            "            1,    1,    1,    1,    1,    1,    2,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   14,  642,    1,   22,    1,\n",
            "            1,    1,    1,    1,    1,    1,  683,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    2,    5,    1,  240,    1,\n",
            "            1,    1,    1,    1,    1,    1,    5,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   43,    1,    1,  279,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   13,    1,    1,    4,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   18,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1, 1341,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,   18,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    4,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
            "tensor(4100.4883)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok_sIWts4N1A",
        "outputId": "46cf3ef6-9e2c-4e8d-f2fd-3889105673fd"
      },
      "source": [
        "batch_val = next(iter(val_iter))\n",
        "print(batch_val.SQL.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7W4Bot_Jy7K",
        "outputId": "90413c5e-a779-437e-d012-a6fb48b49245"
      },
      "source": [
        "print(\"Length of training set: \" + str(len(spider.get('train'))) + '\\n')\n",
        "data_example = spider.get('train')[0]\n",
        "y = data_example['query']\n",
        "x = data_example['question']\n",
        "print(\"Example of training data:\")\n",
        "print('\\n'.join([(str(key) + ': ' + str(data_example[key])) for key in data_example]))\n",
        "\n",
        "#Convert input into numpy -------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training set: 7000\n",
            "\n",
            "Example of training data:\n",
            "db_id: department_management\n",
            "query: SELECT count(*) FROM head WHERE age  >  56\n",
            "question: How many heads of the departments are older than 56 ?\n",
            "query_toks: ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56']\n",
            "query_toks_no_value: ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value']\n",
            "question_toks: ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0jJdm8YW3JC"
      },
      "source": [
        "Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sg3x2TJUE2p"
      },
      "source": [
        "#https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\n",
        "\n",
        "#Gives word vector\n",
        "\n",
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model): #first parameter: total number of unique words. second parameter: the length of the embeddings\n",
        "        super().__init__()\n",
        "        #Create embedding function\n",
        "        self.embed = nn.Embedding(vocab_size, d_model) #can be pretrained too, some extra steps for that\n",
        "    def forward(self, x):\n",
        "        #Embed\n",
        "        return self.embed(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJXUR2Z6W1DA"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kFPUsUcWyl8"
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len = 200, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model #the length of the embeddings\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # create constant 'pe' matrix with values dependant on \n",
        "        # pos and i. This will come to work in forward pass\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        " \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # multiply the values of embeddings with the square of the length of embeddings. To fix vansihing gradients or something ig\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        #add constant to embedding\n",
        "        seq_len = x.size(1)\n",
        "        pe = Variable(self.pe[:,:seq_len], requires_grad=False) #takes values from self.pe according to the length of the input text string\n",
        "        if x.is_cuda:\n",
        "            pe.cuda()\n",
        "        x = x + pe\n",
        "        return self.dropout(x)\n",
        "        #combines input with pe and returns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLufY-00KrA0"
      },
      "source": [
        "Multi Head Attention Layer and Attention Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbL4fCY4Ku5o"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // heads\n",
        "        self.h = heads\n",
        "        \n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, q, k, v, scale_factor, mask=None):\n",
        "        \n",
        "        bs = q.size(0)\n",
        "        \n",
        "        # perform linear operation and split into h heads\n",
        "        \n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "        \n",
        "        # transpose to get dimensions bs * h * sl * d_model\n",
        "       \n",
        "        k = k.transpose(1,2)\n",
        "        q = q.transpose(1,2)\n",
        "        v = v.transpose(1,2) * scale_factor\n",
        "        # calculate attention using function we will define next\n",
        "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
        "        \n",
        "        # concatenate heads and put through final linear layer\n",
        "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
        "        #use the scale factor as mentioned in dt_fixup\n",
        "        output = self.out(concat) * scale_factor\n",
        "    \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT-ci_07a6zr"
      },
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "    \n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "    \n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "        \n",
        "    output = torch.matmul(scores, v)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bouOfmge8Agt"
      },
      "source": [
        "class Norm(nn.Module):\n",
        "    def __init__(self, d_model, eps = 1e-6):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.size = d_model\n",
        "        # create two learnable parameters to calibrate normalisation\n",
        "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "        self.eps = eps\n",
        "    def forward(self, x):\n",
        "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
        "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "        return norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZtROWZ8899E"
      },
      "source": [
        "Encoder Decoder Layer Classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp0YxjuxGQsn"
      },
      "source": [
        "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        #self.norm_1 = Norm(d_model)\n",
        "        #self.norm_2 = Norm(d_model)\n",
        "        self.attn = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, scale_factor, mask):\n",
        "        x2 = x #self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn(x2,x2,x2,scale_factor,mask))\n",
        "        x2 = x #self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.ff(x2))\n",
        "        return x\n",
        "    \n",
        "# build a decoder layer with two multi-head attention layers and\n",
        "# one feed-forward layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        #self.norm_1 = Norm(d_model)\n",
        "        #self.norm_2 = Norm(d_model)\n",
        "        #self.norm_3 = Norm(d_model)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "        \n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model)\n",
        "    def forward(self, x, e_outputs, scale_factor, src_mask, trg_mask):\n",
        "        x2 = x #self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, scale_factor, trg_mask))\n",
        "        x2 = x #self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, scale_factor, src_mask))\n",
        "        x2 = x #self.norm_3(x)\n",
        "        x = x + self.dropout_3(self.ff(x2))\n",
        "        return x\n",
        "# We can then build a convenient cloning function that can generate multiple layers:\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACWddVOGxRj"
      },
      "source": [
        "#change N to tune the number of multi headed attention layers\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "        #self.norm = Norm(d_model)\n",
        "    def forward(self, src, scale_factor, mask):\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, scale_factor, mask)\n",
        "        return x #self.norm(x)\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "        #self.norm = Norm(d_model)\n",
        "    def forward(self, trg, e_outputs, scale_factor, src_mask, trg_mask):\n",
        "        x = self.embed(trg)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs, scale_factor, src_mask, trg_mask)\n",
        "        return x #self.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgjnYIti79o6"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
        "        super().__init__() \n",
        "        # We set d_ff as a default to 2048\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)#*scale_factor\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7cDwO5HSjP"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, scale_factor, d_model, N, heads):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "        self.scale_factor = scale_factor\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        encoder_outputs = self.encoder(src, self.scale_factor, src_mask)\n",
        "        decoder_output = self.decoder(trg, encoder_outputs, self.scale_factor, src_mask, trg_mask)\n",
        "        output = self.out(decoder_output)\n",
        "        return output\n",
        "# we don't perform softmax on the output as this will be handled \n",
        "# automatically by our loss function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ1W5CIkHnue"
      },
      "source": [
        "#this is what will have to be tuned\n",
        "from math import sqrt\n",
        "\n",
        "d_model = 512\n",
        "heads = 8\n",
        "N = 6\n",
        "scale_factor = 1/(2 * sqrt(N) * max_inp_norm) #scale factor as defined in dt fixup\n",
        "src_vocab = len(EN_TEXT.vocab)\n",
        "trg_vocab = len(SQL_TEXT.vocab)\n",
        "model = Transformer(src_vocab, trg_vocab, scale_factor, d_model, N, heads)\n",
        "model.to(device)\n",
        "for p in model.parameters():\n",
        "  if p.dim() > 1:\n",
        "    nn.init.xavier_uniform_(p) #xavier initialisation as defined in dt fixup\n",
        "# this code is very important! It initialises the parameters with a\n",
        "# range of values that stops the signal fading or getting too big.\n",
        "# See this blog for a mathematical explanation.\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkmzTnWsN2G_",
        "outputId": "3595a1ca-e675-41c5-9ade-fe392c7d125c"
      },
      "source": [
        "len(train_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVgF7qjgIA4"
      },
      "source": [
        "r_loss = []\n",
        "val_loss = []\n",
        "\n",
        "def train_model(epochs, print_every=50):\n",
        "    \n",
        "    #model.train()\n",
        "    \n",
        "    start = time.time()\n",
        "    temp = start\n",
        "    \n",
        "    total_loss = 0\n",
        "    val_total_loss = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            #print('..')\n",
        "            src = batch.Text.transpose(0,1)\n",
        "            src = src.to(device)\n",
        "            trg = batch.SQL.transpose(0,1)\n",
        "            trg = trg.to(device)\n",
        "            # the SQL sentence we input has all words except\n",
        "            # the last, as it is using each word to predict the next\n",
        "            \n",
        "            trg_input = trg[:, :-1]\n",
        "\n",
        "            # the words we are trying to predict\n",
        "            \n",
        "            targets = trg[:, 1:].contiguous().view(-1)\n",
        "            \n",
        "            # create function to make masks using mask code above\n",
        "            \n",
        "            src_mask, trg_mask = create_masks(src, trg_input)\n",
        "            \n",
        "            trg_input = trg_input.to(device)\n",
        "            src_mask = src_mask.to(device)\n",
        "            trg_mask = trg_mask.to(device)\n",
        "            \n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            \n",
        "            target_pad = SQL_TEXT.vocab.stoi['<pad>']\n",
        "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), targets, ignore_index=target_pad)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "            total_loss += float(loss)\n",
        "            if (i + 1) % print_every == 0:\n",
        "                loss_avg = total_loss / print_every\n",
        "                r_loss.append(loss_avg)\n",
        "                print(\"time = %dm, epoch %d, iter = %d, train loss = %.3f, %ds per %d iters\" % ((time.time() - start) // 60, epoch + 1, i + 1, loss_avg, time.time() - temp,print_every))\n",
        "                total_loss = 0\n",
        "                temp = time.time()\n",
        "        \n",
        "        #Calculations for validation loss\n",
        "        model.eval()\n",
        "        for i, batch in enumerate(val_iter):\n",
        "            src_val = batch.Text.transpose(0,1)\n",
        "            src_val = src_val.to(device)\n",
        "            trg_val = batch.SQL.transpose(0,1)\n",
        "            trg_val = trg_val.to(device)\n",
        "            # the SQL sentence we input has all words except\n",
        "            # the last, as it is using each word to predict the next\n",
        "            \n",
        "            trg_input_val = trg_val[:, :-1]\n",
        "\n",
        "            # the words we are trying to predict\n",
        "            \n",
        "            targets_val = trg_val[:, 1:].contiguous().view(-1)\n",
        "            \n",
        "            # create function to make masks using mask code above\n",
        "            \n",
        "            src_mask_val, trg_mask_val = create_masks(src_val, trg_input_val)\n",
        "            \n",
        "            rrg_input_val = trg_input_val.to(device)\n",
        "            src_mask_val = src_mask_val.to(device)\n",
        "            trg_mask_val = trg_mask_val.to(device)\n",
        "            \n",
        "            v_preds = model(src_val, trg_input_val, src_mask_val, trg_mask_val)\n",
        "            target_pad = SQL_TEXT.vocab.stoi['<pad>']\n",
        "            v_loss = F.cross_entropy(v_preds.view(-1, v_preds.size(-1)), targets_val, ignore_index=target_pad)\n",
        "            \n",
        "            val_total_loss += float(v_loss)\n",
        "            #if (i + 1) % print_every == 0:\n",
        "        loss_avg = val_total_loss / len(val_iter)\n",
        "        val_loss.append(loss_avg)\n",
        "        print(\"epoch %d, validation loss = %.3f\" % (epoch + 1, loss_avg))\n",
        "        val_total_loss = 0\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GKWHuhrRI_p"
      },
      "source": [
        "# Masking\n",
        "\n",
        "def create_masks(src,target_input):\n",
        "  #batch = next(iter(train_iter))\n",
        "  input_seq = src\n",
        "  input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
        "  # creates mask with 0s wherever there is padding in the input\n",
        "  input_msk = (input_seq != input_pad).unsqueeze(1)\n",
        "  input_msk.to(device)\n",
        "\n",
        "  target_seq = target_input\n",
        "  #target_seq = batch.SQL.transpose(0,1)\n",
        "  target_pad = SQL_TEXT.vocab.stoi['<pad>']\n",
        "  target_msk = (target_seq != target_pad).unsqueeze(1)\n",
        "  size = target_seq.size(1) # get seq_len for matrix\n",
        "  nopeak_mask = np.triu(np.ones((1, size, size)),\n",
        "  k=1).astype('uint8')\n",
        "  nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0).to(device)\n",
        "  target_msk = target_msk & nopeak_mask\n",
        "  target_msk.to(device)\n",
        "  \n",
        "  return input_msk,target_msk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "cmeRPss7pZ_F",
        "outputId": "a6a2c9f8-da88-4354-cce3-450d13af53f2"
      },
      "source": [
        "train_model(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time = 0m, epoch 1, iter = 50, train loss = 4.609, 8s per 50 iters\n",
            "time = 0m, epoch 1, iter = 100, train loss = 3.708, 8s per 50 iters\n",
            "epoch 1, validation loss = 3.246\n",
            "time = 0m, epoch 2, iter = 50, train loss = 6.297, 16s per 50 iters\n",
            "time = 0m, epoch 2, iter = 100, train loss = 3.122, 8s per 50 iters\n",
            "epoch 2, validation loss = 3.058\n",
            "time = 0m, epoch 3, iter = 50, train loss = 5.573, 16s per 50 iters\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b605afb000fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-671f340951d9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, print_every)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtarget_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQL_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAFGbzffRgBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "455f0631-eb95-4aa7-99dc-529368b44682"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "fig.suptitle('First Half And Second Half Loss vs Epochs for N = 2: Training')\n",
        "X_axis = np.linspace(1, 9, 9)\n",
        "ax1.plot(X_axis, r_loss[::2], \"b\", label=\"Train\")\n",
        "ax1.plot(X_axis, val_loss, \"r\", label=\"Validation\")\n",
        "ax1.legend(loc=\"upper right\")\n",
        "ax2.plot(X_axis, r_loss[1::2], \"b\", label=\"Train\")\n",
        "ax2.plot(X_axis, val_loss, \"r\", label=\"Validation\")\n",
        "ax2.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEVCAYAAAABwEUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5gUVdaH38MQBskZJTjIKBjIoCgmxIAMggFXUVcRFUFWxXUXV10V066B3TWjCJ8YWFFRURFRDKyuAQUFDOCaQEAFRElKlPP9caqhGSb0TIfqnj7v89TT1V23q05X3/rVrXPPPVdUFcdxHKdiUylsAxzHcZzk42LvOI6TBbjYO47jZAEu9o7jOFmAi73jOE4W4GLvOI6TBZRb7EVkvYjslUhjEoWI5ImIikjl4H0TEXlTRNaJyD9ScPxRIvJYso+TLERkpoicn8T9q4jkB+vVReQFEVkjIk8l65jZRPT5jXM/J4nIkuBa75QI27IJEblKRMYlumx5KVXsRWSRiGwI/vDIsoeq1lTVr8t6QBE5UkSWllJmgojcVOiznQS8jAwBfgRqq+rlJRx3VHCMg8pxjJgJ/thvgnO5VESeSObxEklxN7I4BGYA0ARooKqnxnq8TKGY6+eesO2KkdHAH4Jr/aN4dxY0IjaKSIuoz44WkUXx7rvQcfYRkedEZKWI/CQiL4tImxi/+1LU/7RFRDZHvb+/LHao6t9UNaZGU1nKlpdYW/YnBH94ZPmupMIikpMA2xLJnsBnWsIIMhER4Gzgp+A1KYjIOcDvgaNVtSbQFXgtWcfLAPYE/qeqW8M2JIkUvn7+ELZBMbIn8Gl5vliCBvwCXFNui2KjLvA80AZrSLwPPBfLF1X1+Mj/BEwEbov634ZGypWz0Rkq8bhxoh/FJ4jIGBGZJiK/AD1FpI+IfBa4TpaJyJ9EpAbwErBH9FNCOY9fICIficja4FFzVDHlJgDnACOD4x1dzC4PA3YHLgFOF5GqUfsYJCL/FZHRIvJz0Co/Pmp7KxH5T/BbZwANSzC9G/Cyqn4FoKo/qOrYqH3VEZHxIvJ9cN5uir5wROQCEVkQHOszEekcfL5v0HJaLSKfiki/6HMgIveKyIvB92aJSOuo7ceIyEIxV8o9gJRgf6mIyIEi8m5gy/cick/0+Ywqdz1wLXBa8N+cV8bj9At+6+rgt+8bte2K4PytE5HPRaRXlG2zg3qzXET+Wcy+F4hI36j3lYOWYmcRyRWRx0RkVXDsD0SkSVlsD/Y5SETeDs7PmuA/6BW1fQ8ReT5onX4pIhdEbcsRe0L8KviNcySqxQwcLSJfBPbdGzRmEJH8oK6uEZEfpYinShGpJiLrgRxgnoh8FXxeWh3bSQOK+dl3AQOj61+iUdX3VXW8qv6kqluAfwFtRKRBPPsV07zhIvIF8EXw2Z2B/qwN/oPDospvfyqVHZ6Jc0Tk2+DcX13OstVF5GExLVogIiOlFG9J5MSUuACLsFZo4c8VyA/WJwBrgB7YDSQX+B44LNheD+gcrB8JLC3lmBOAmwp9lhccs3LUftoFx2sPLAdOLKbsLvsr4pjjgSeBKsAq4JSobYOALcAF2AUwDPgOkGD7u8A/gWrA4cA64LFijnMW9vTwZ6xVn1No+7PAA0ANoDHWKrkw2HYqsAy7YQiQj7W+qgBfAlcBVYGjAhvaRP3+VcCBQGWsxTIp2NYwKDsg2M9lwFbg/GLsH1XUbytUH7oA3YNj5QELgBHFlC1yfzEcbx+slXhMYPfI4BxUxVp0S4A9oupD66j/6vfBek2gezHHvRaYGPW+AFgQrF8IvADsFtSHLpiLMObrJ6pebQ3OeRXgNOw6qh9sfxO4D7ueOgIrgaOCbX8GPg5+qwAdMFdY5PxOxVq4LYPv9Q62PQ5czY7r9NASzn30/xRLHdtJA4rY30zgfOxaeSz47GhgUQk2zAdWF7PcV5p+Bfs4Efg+6v2hwOoYvjeBKN0IzscMoD5QPep6boDV9cuBHyK/nai6yw5NehCoHvxfm4B9y1H2FuA/mK42D85RiZqqqjGL/fqoEzyliIowAXik0Pe+xS6K2oU+P7I0w4L9bSz0x64lSsCL+M4dwL8KnayYxB67aNey42bxAPBcoYvyy0LlFWiKXUxbgRpR2/9NyQJ2JvAqJlargCuCz5sEf2r1qLIDgTeC9ZeBS4vY32FBJasU9dnjwKio3z8ualsfYGGwfjbwXtQ2AZZSsthvZtcLb3t9KOI7I4BnixGRUaWcqyK3Y66AJ6PeV8JuhEdiN8EVmJBUKfS9N4HrgYal1MF8TMx2C95PBK4N1gcD7wDty3H9rAYuiKpX2xsNwWfvY26+FsBvQK2obX8HJgTrnwP9izmmEiXiWCPmL8H6I8BYoHkMtkf/T7HUsUdK2d9MTOwbYTeG/SlF7ONdMDFcBgwsx3cnsKvYH1XKd34GOhSuu+zQpOZRZd8HTi9H2a+B46K2nU8MYh+rG+dEVa0bLCcWU2ZJofenYKKyOHhsPDjGY0UYHXXMuljrfTsicpCIvBE8Wq8BhlKy+6QkTsIEe1rwfiJwvIg0iirzQ2RFVX8NVmsCewA/q+ovUWUXl3QwVZ2oqkdjLa+hwI0ichw7WunfB4/Kq7EbT+Pgqy2Ar4rY5R7AElXdVsiGZkXZD/wa2L79u1G2Kbv+l4V5Mvq/Cf6f7Yh1kE0VkR9EZC3wN8r/3xTHHkSd5+C3LwGaqeqX2A1mFLBCRCbJDnfhedhTwcLA/dKXIgj2sQA4QUR2A/phN3GAR7Eb7yQR+U5EbhORKiXYemKh8/Vg1LZlwTmPsDj4bXsAP6nqukLbIv9pcXUhQnH/90jshv5+4IoZXMI+oomljpVWbwBQ1ZXAPcANMR67XATX7yvYE8DjCdrtTr9RzD29IHCLrQbqUHJdL+5/KUvZna7ZwjYVRyLj7HWnN6ofqGp/TKimYK2LXcrFwb+xTpgWqloHuJ/y+5rPwU7ktyLyA/AUJrpnxPDd74F6Yv0REVrGclBV3aKqT2GPYQdgf9omrNUZEYbaqrp/8JUlQFG+zu+AFiIS/X+2xFo0sdgfHR0h0e/LyRhgIbC3qtbGHv3j6gcogu+wmyOwk93LAFT136p6aFBGgVuDz79Q1YFYvbwVmFzov4vmcezJqj/Wwf9lsI8tqnq9qu4HHAL0pfyd+s0i/vSAlsFv+w6oLyK1Cm2L/KfF1YUSUesjukBV98CevO+T2KKoYqljZbm2b8f8+l1KKhTckNYXsxQbHSMi9TChf15Vby6DXaWx/TcG/vmRwO+AekGjZw2Jr+uF+R57YokQ0/WalEFVIlJVRM4UkTpqHSRrgUiLYDnQQETqxHmYWljLZ6OIHEhswlyUrc2AXtgF2zFYOmBCUOoFrKqLgdnA9cHvPhQ4oYTjDRLrXK4lIpXEOnr3B2ap6vdYBf2HiNQOtrcWkSOCr48D/iQiXcTIF5E9gVnYnX+kiFQRkSMDGybFcApeBPYXkZPFIgwuwdxT8VAL+8/Xi0hbrI8jHiqJdYpGlmpY46FARHoFrerLsRvlOyLSRkSOCsptBDYQ1D8ROUtEGgUt1NXB/rftekjAzt+xgf2RVj0i0lNE2ol1nK/F+nOK20dpNAYuCf63U4F9gWmqugRzFf09+M3tsaeSSBjqOOyJcO+gLrSXGDogReRUEYkIxc+YeMViezx1bBdUdTXwD0wsSyq3v+4cyRS9DC3qOyJSG3vyeltV/1Ie+2KkFuYRWAlUFpFrgdpJPF6EJ4ErRaReoF8xRXclcwTt74FFwWP8UMxPjaouxFpMXweuinJF4wAXATeIyDqsM+3JUsqXZOdcVX0laPX8oKo/YFED7UXkgBj2cQZwENbxeh3mFy2OtVhL91tMbG4Dhqnqf4PtZ2MdYJ9hF+NkLEqI4CngZkx41mFPTPVVdTN24R2PjSe4Dzg7ONcloqo/Yh2/t2D9B3sDb8fwm0viT9g5WYd1MsU7jmAgJtiR5StV/RzrHLsb+80nYCGOm7GO8luCz3/ABPXKYF+9gU/Fok3uxPygG4o6aHDzfRdrvUf/hqbY/7IWc/X8B3PtFMcLhVqkz0Ztm4Wd8x+x/3aAqq6K+t15WKv6WeA6VX012PZPrM6/EtgxHuvMK41uwKzg9z+P9QGVOl4mnjpWAndi/RKJ5iTsd55b6Ly3BGuRB78/Xl4GpgP/w1xaG4nRpRInN2D9at9gfX+TsYZOiUSiSRzHSTEiMgjrCD80bFuczEVEhmGNliNKKue5cRzHcTIIEdldRHoEbt42mAvz2dK+l3GjwBzHcbKcqliUXivMFTwJc6uViLtxHMdxsgB34ziO42QBLvaO4zhZgIu94zhOFuBi7ziOkwW42DuO42QBLvaO4zhZgIu94zhOFuBi7ziOkwW42DuO42QBLvaO4zhZgIu94zhOFuBi7ziOkwW42DuO42QBLvaO4zhZQNz57EXkMuB8bC7Lj4FzVXVjceUbNmyoeXl58R7WcYpkzpw5P6pqo1Qf1+u1k0wSUa/jEvtgsttLgP1UdYOIPAmcDkwo7jt5eXnMnj07nsM6TrGIyOIwjuv12kkmiajXiXDjVAaqi0hlYDdscmTHcRwnjYhL7FV1GTAa+Bb4Hlijqq8ULiciQ0RktojMXrlyZTyHdBzHccpBXGIvIvWA/thciHsANUTkrMLlVHWsqnZV1a6NGqXcneo4jpP1xNtBezTwjaquBBCRZ4BDgMfiNawisWXLFpYuXcrGjcX2WztlJDc3l+bNm1OlSpWwTclqvG4nlmTW63jF/lugu4jsBmwAegHeS1WIpUuXUqtWLfLy8hCRsM3JeFSVVatWsXTpUlq1ahW2OVmN1+3Ekex6Ha/PfhYwGfgQC7usBIxNgF0Vio0bN9KgQQO/GBKEiNCgQYNytyZFZJGIfCwic0Vkl8aJiBwpImuC7XNF5Nq4ja6geN1OHPHW69KIO85eVa8DrkuALRUavxgSSwLOZ09V/bGE7W+pat94D5INeN1OHMk8lxVqBO306TB3bthWOM4OXn8dRo0K2wrHqUBiv3Ah9OsHf/hD2JakH6tWraJjx4507NiRpk2b0qxZs+3vN2/eXOJ3Z8+ezSWXXJIiS1OGAq+IyBwRGVJMmYNFZJ6IvCQi+xdVIJaQ4rffhuuvhw0bEmS5sxNet2MnbjdOOqAKw4bBli3w7rvw009Qv37YVqUPDRo0YG7wyDNq1Chq1qzJn/70p+3bt27dSuXKRVeFrl270rVr15TYmUIOVdVlItIYmCEiC1X1zajtHwJ7qup6EekDTAH2LrwTVR1L0EfVtWtXLepA+fn2+s03sN9+if0RjtftslAhWvYTJ8LMmTB4MGzbBi+/HLZF6c+gQYMYOnQoBx10ECNHjuT999/n4IMPplOnThxyyCF8/vnnAMycOZO+fc11PWrUKAYPHsyRRx7JXnvtxV133RXmTyg3wWBAVHUF8CxwYKHta1V1fbA+DagiIg3Lc6zWre31yy/jMNgpE9lct0si41v2P/8Mf/wjdO8ODzwAL7wAL74IAweGbVnRjBiR+H6Fjh3hjjvK/r2lS5fyzjvvkJOTw9q1a3nrrbeoXLkyr776KldddRVPP/30Lt9ZuHAhb7zxBuvWraNNmzYMGzYso2LdRaQGUElV1wXrxwI3FCrTFFiuqioiB2KNolXlOV6kZZ8NYu91O73JeLG/6ipz28yYAZUrQ+/eMG0a/PYb5OSEbV16c+qpp5ITnKQ1a9Zwzjnn8MUXXyAibNmypcjvFBQUUK1aNapVq0bjxo1Zvnw5zZs3T6XZ8dIEeDaIeqgM/FtVp4vIUABVvR8YAAwTka3Y+JHTVbVIN01p1K8PdevCV18lxngnNrK0bpdIRov9e+9Za37ECOjQwT4rKIBHH4VZs+CQQ8K1ryjK00pJFjVq1Ni+fs0119CzZ0+effZZFi1axJFHHlnkd6pVq7Z9PScnh61btybbzISiql8DHYr4/P6o9XuAexJ1zPz87GjZe91ObzLWZ791KwwdCnvsYdEOEY47zlr006aFZ1smsmbNGpo1awbAhAkTwjWmgpGf7y37MPG6bWSs2N9zD8ybB3feCbVq7fi8bl3o0cP89k7sjBw5kiuvvJJOnTpVuBZN2LRuDYsWWbSYk3q8bgeoakqXLl26aLwsWaJas6Zqnz6q27btuv3WW1VBdenSuA+VED777LOwTaiQFHVegdma4jqtpdTrhx6y+vjll/H93nTE63biSVa9zsiW/YgR5sa5+24oanRxnz726q4cJx3w8EsnHcg4sZ82DZ5+Gq65Bvbaq+gy++8PLVu62DvpQTaFXzrpS0aJ/a+/WjqEffeFqEFyuyBiUTkzZsCmTamzz3GKomlT2G0376R1wiWjxP5vf7Nh5/fdB1Wrlly2oAB++QXefLPkco6TbETMleMteydMMkbsFyyA226Ds8+GYsJkd6JnT8jN9agcJz3w8EsnbDJC7FXhoougZk24/fbYvrPbbib4LvZOOtC6tYn9tm1hW+JkKxkh9o89ZonObrkFGjeO/XsFBfbo/MUXSTMtI+jZsycvF8oOd8cddzBs2LAiyx955JHMnm0TOPXp04fVq1fvUmbUqFGMHj26xONOmTKFzz77bPv7a6+9lldffbWs5lcI8vOt/2jZsrAtqVh43Y6dtBf7n36Cyy+3RGfnn1+27xYU2Gu2t+4HDhzIpEmTdvps0qRJDIwhW9y0adOoW7duuY5b+IK44YYbOProo8u1r0wnEn7prpzE4nU7dtJe7K+80gT//vuhUhmtzcuzHOLZLvYDBgzgxRdf3D6Zw6JFi/juu+94/PHH6dq1K/vvvz/XXVf0zJJ5eXn8+KPN3nfzzTezzz77cOihh25PEwvw4IMP0q1bNzp06MApp5zCr7/+yjvvvMPzzz/Pn//8Zzp27MhXX33FoEGDmDx5MgCvvfYanTp1ol27dgwePJhNQdhUXl4e1113HZ07d6Zdu3YsXLgwmacmZXj4ZXLwuh07aZ0I7d13YexYS2HcYZfUVbHRp4+lVFi3bue0CqERQh7Y+vXrc+CBB/LSSy/Rv39/Jk2axO9+9zuuuuoq6tevz2+//UavXr2YP38+7du3L3Ifc+bMYdKkScydO5etW7fSuXNnunTpAsDJJ5/MBRdcAMBf//pXxo8fz8UXX0y/fv3o27cvAwYM2GlfGzduZNCgQbz22mvss88+nH322YwZM4YRI0YA0LBhQz788EPuu+8+Ro8ezbhx4xJxlkKlRQuoUqWCt+y9bqd13U7blv3WrTb7VLNm8c3hWVBgOUleey1hpmUk0Y+7kcfcJ598ks6dO9OpUyc+/fTTnR5LC/PWW29x0kknsdtuu1G7dm369eu3fdsnn3zCYYcdRrt27Zg4cSKffvppibZ8/vnntGrVin322QeAc845hzejYmRPPvlkALp06cKiRYvK+5PTipwcaNXKW/bJwOt2bKRty/7uuy3R2dNPx9ci79ED6tQxV86JJybOvnITUh7Y/v37c9lll/Hhhx/y66+/Ur9+fUaPHs0HH3xAvXr1GDRoEBs3bizXvgcNGsSUKVPo0KEDEyZMYObMmXHZGkk1W9HSzEYiciosXrdLJcy6nZYt+yVLLB1CQQGcdFJ8+6pSBY491lInlG/6iYpBzZo16dmzJ4MHD2bgwIGsXbuWGjVqUKdOHZYvX85LL71U4vcPP/xwpkyZwoYNG1i3bh0vvPDC9m3r1q1j9913Z8uWLUycOHH757Vq1WLdunW77KtNmzYsWrSIL4Nm7qOPPsoRRxyRoF+avkTy2mdzPUwGXrdjIy3FfsQIi0cuLtFZWenTB777LvHuxExj4MCBzJs3j4EDB9KhQwc6depE27ZtOeOMM+jRo0eJ3+3cuTOnnXYaHTp04Pjjj6dbt27bt914440cdNBB9OjRg7Zt227//PTTT+f222+nU6dOfBXVpM3NzeWhhx7i1FNPpV27dlSqVImhQ4cm/genGfn51ne0cmXYllQ8vG7HQLxpM8u6lJbieOpUSwf7t7+VJSloyfzwg+3zppsSt8+y4Glgk0OmpDiOEKnb77xTzh+chnjdTjxZkeI4OtHZ5Zcnbr9NmkC3bh6C6YSLh186YZJWYn/TTTajz5gxpSc6KysFBTZnbRBW6zgpJy/P3JIVupPWSVvSRuw/+wxGj7ZEZ8noz+jTxzrGpk9P/L5jQb1XLqFk4vmsVs3mWahoLftM/C/SlWSey7QQ+/IkOisrXbqYOycMV05ubi6rVq3yiyJBqCqrVq0iNzc3bFPKTEULv/S6nTiSXa/TIs5+7lx4+23LU1+WRGdloVIlOP54eO45G7BVOYW/vHnz5ixdupSVHoaRMHJzc2nevHnYZpSZ/Hx45pmwrUgcXrcTSzLrdVqIfadO5saJJItKFgUFMGGC+e4PPTS5x4qmSpUqtGrVKnUHdNKW/HzrN1qzxgb7ZTpetzOHtHDjAOy9d9kTnZWVY46xFr1H5Thh4dkvnbCIS15FpI2IzI1a1orIiEQZl2jq1LEWvYt9diMii0Tk46DOzi5iu4jIXSLypYjMF5HOiTq2h186YRGX2Kvq56raUVU7Al2AX4FnE2JZkigogI8/tpQMTlbTM6i7XYvYdjywd7AMAcYk6qB77WWv3rJ3Uk0iHSe9gK9UdXEC95lwIhOaTJsWrh1OWtMfeCQYvPgeUFdEdk/EjmvWhKZNvWXvpJ5Eiv3pwOMJ3F9SaNvWUs26KyerUeAVEZkjIkOK2N4MiH72Wxp8thMiMkREZovI7LJEo1S08EsnM0iI2ItIVaAf8FQx28t1USQDERtg9dprUM6sp07mc6iqdsbcNcNF5PDy7ERVx6pqV1Xt2qhRo5i/F8l+6TipJFEt++OBD1V1eVEby3tRJIuCAsvDE2dqaidDUdVlwesKrI/pwEJFlgEtot43Dz5LCPn5NvH4hg2J2qPjlE6ixH4gGeDCiXDkkVC9uvvtsxERqSEitSLrwLHAJ4WKPQ+cHUTldAfWqOr3ibIhEn759deJ2qPjlE7cYh9cMMcAGTMusHp16NXL/PY+yjvraAL8V0TmAe8DL6rqdBEZKiKRxOPTgK+BL4EHgYsSaYCHXzphEPcIWlX9BWiQAFtSSp8+MHUqfP65ddo62YGqfg3sMn29qt4fta7A8GTZ4AOrnDBImxG0qSYSgulROU6qqV8f6tXzlr2TWrJW7Fu2hAMOcL+9Ew4efumkmqwVe7DW/Ztvwtq1YVviZBsefumkmqwX+61bYcaMsC1xso38fFi8GLZsCdsSJ1vIarE/+GCoW9f99k7qad0afvvNBN9xUkFWi33lynDccea337YtbGucbMLDL51Uk9ViD+bKWb4cPvoobEucbMLDL51Uk/Vi37u35ctxV46TSpo2hd1285a9kzqyXuwbNYIDD3Sxd1KLiIdfOqkl68UezJXzwQewYkXYljjZhIdfOqnExR4Te1WYPj1sS5xsIj/fkqF5cICTClzsgU6dYPfd3ZXjpJbWrWHTJkt37DjJxsUe858efzy8/LIPcnFSh4dfOqnExT6goADWrIF33gnbEidb8PBLJ5W42AcccwxUqeKuHCd1tGhhdc5b9k4qcLEPqFULDj/cs2A6qSMnB1q18pa9kxpc7KMoKIBPP/V8JU7q8PBLJ1W42EfRp4+9uivHSRURsffpMZ1k42IfxT77WKeZi72TKlq3hvXrYeXKsC1xKjou9lGIQL9+8MorMGtW2NY42YCHXzqpwsW+EH/9KzRvDgMGeGvLST4efumkChf7QtSvD08/bUJ/5pk2wYTjJIu8PKhUyVv2TvJxsS+Czp3h3nttusLrrw/bGqciU62axdt7y95JNi72xXDeeTB4MNx4o3fYOsnFwy+dVOBiXwL33AMdO8JZZ8E334RtjVNRcbF3UoGLfQlUr27+e4BTToGNG8O1x0kcIpIjIh+JyNQitg0SkZUiMjdYzk+mLa1bw6pVsHp1Mo/iZDsu9qWw117w6KM2R+3FF4dtjZNALgUWlLD9CVXtGCzjkmlIJPzS/fZOMnGxj4G+feHqq2HcOPi//wvbGideRKQ5UAAkVcRjxcMvnVTgYh8j118PvXrB8OHWyncymjuAkUBJc0SdIiLzRWSyiLQoqoCIDBGR2SIye2UcgzIiYu9+eyeZuNjHSE4OPP44NGxo/vuffw7bIqc8iEhfYIWqzimh2AtAnqq2B2YADxdVSFXHqmpXVe3aqFGjcttUowY0bepi7yQXF/sy0KgRPPUULF0KZ5/tc4dmKD2AfiKyCJgEHCUij0UXUNVVqropeDsO6JJso/Lz3Y3jJBcX+zLSvTv8618wdSrcckvY1jhlRVWvVNXmqpoHnA68rqpnRZcRkd2j3vaj5I7chODhl06ycbEvBxddBGecAddcA6++GrY1TiIQkRtEpF/w9hIR+VRE5gGXAIOSffzWreG77+DXX5N9JCdbiVvsRaRu0Im1UEQWiMjBiTAsnRGBsWNh331h4EBz6ziZh6rOVNW+wfq1qvp8sH6lqu6vqh1UtaeqLky2LZHwy6+/TvaRnGwlES37O4HpqtoW6EAKHnnTgRo1bMDVxo1w6qmweXPYFjmZjIdfOskmLrEXkTrA4cB4AFXdrKpZMw6wTRt46CF47z24/PKwrXEyGc9r7ySbeFv2rYCVwEPB0PNxIlKjcKFExSOnIwMGmNDfcw/8+99hW+NkKvXq2eJi7ySLeMW+MtAZGKOqnYBfgL8ULpSoeOR05e9/h8MOgwsusAnLHac8ePilk0ziFfulwFJVjUziNxkT/6yiShV44gmoVQtOPhnWrg3bIicT8fBLJ5nEJfaq+gOwRETaBB/1Aj6L26oMZPfd4cknrWV23nmgGrZFTqbRujUsXuyd/U5ySEQ0zsXARBGZD3QE/paAfWYkhx8Ot94KkyfbwCvHKQv5+TYqe/HisC1xKiKV492Bqs4FuibAlgrBH/8I77wDI0dC27bQp0/YFjmZQnT45d57h2uLU/HwEbQJRsTCMTt0MP/9yy+HbZGTKXj4pZNMXOyTQO3aNln5vvvCiSfCa6+FbZGTCTRpYoP1XOydZOBinyTq1zfB33tvOOEEmDkzbK7Ptx4AAB3SSURBVIucdEfEXDkefukkAxf7JNKwoSVKa9UKCgrgrbfCtshJdzz80kkWLvZJpnFjc+O0aGGdte+8E7ZFTkp55RUYMSLm4q1bWzK0335Lok1OVuJinwKaNoXXX7dY/N69Ydas0r/jVBA++QTuvBPmzYupeH6+xdkvW5Zku5ysw8U+Reyxhwl+o0Zw3HEwe3bYFjkp4dxzoXp1uPfemIp79ksnWbjYp5DmzeGNNyzh1THH+MTlWUG9enDmmfDYYzFNXOzhl06ycLFPMS1bmuDXrg1HHx3z072TyQwfDhs2wIQJpRZt3txyLbnYO4nGxT4E8vLMpVO9ugn+J5+EbZGTVDp2hB49zJVTyiz1OTmw117uxnESj4t9SLRubS38KlWgVy9YkBXze2Uxw4ebgscwpLp1a2/ZO4nHxT5E9t7bBF8EjjoKPv88bIucpHHKKTZENoaO2khee8+c6iQSF/uQadPGXDq//WaC7y26CkrVqnDhhTBtWqmziufnw/r1sGJFimxzsgIX+zRgv/1M8Ddtgp49S9UCJ1MZMgQqVYIxY0os5uGXTjJwsU8TDjjARtr++qsJ/qJFYVvkJJxmzSwV6vjx9kcXg4dfOsnAxT6N6NDBkqetXWsunSVLwrbISTjDh1u8/aRJxRbJy7MHABd7J5G42KcZnTtbOpVVq6yF74/yyUFEckTkIxGZWsS2aiLyhIh8KSKzRCQvYQc+/HB7jLv77mJ7YKtWtfEY/t87icTFPg3p1s0i9FassA7cM87w0bZJ4FKguIDX84CfVTUf+Bdwa8KOKgJ/+APMnQvvvltsMQ+/dBKNi32a0r07fPaZJUx84QVr8R9zjLX6PSQvPkSkOVAAjCumSH/g4WB9MtBLRCRhBpx5pg2hLiEMMxJ+6TiJwsU+jWneHEaPNt/9LbfAp59aErVOnWDiRNiyJWwLM5Y7gJFAccNZmwFLAFR1K7AGaJCwo9esaQnSnnoKli8vskh+vrnyVq9O2FGdLMfFPgOoWxeuuAK++Qb+7/8sBe5ZZ5kg3HGHxWQ7sSEifYEVqjonAfsaIiKzRWT2ypUry/bliy6yu/WDDxa52cMvnUTjYp9BVKtmDcJPPjHXzp57wmWX2cQoV10FP/wQtoUZQQ+gn4gsAiYBR4nIY4XKLANaAIhIZaAOsKrwjlR1rKp2VdWujRo1KpsV++wDxx4L999f5COah186icbFPgOpVAn69oU334T33rPcOrfcYuJ/wQWedqEkVPVKVW2uqnnA6cDrqnpWoWLPA+cE6wOCMonvKRk+3GYpee65XTbttZe9utg7icLFPsM56CCYPNkEfvBgePRRaNsWTjwR3n47bOsyBxG5QUT6BW/HAw1E5Evgj8BfknLQggK7QxfRUVujhs1s5m4cJ1G42FcQ9t7bRuF/+y1cc41Nbn7ooXDIIfDssz6naVGo6kxV7RusX6uqzwfrG1X1VFXNV9UDVTU5CSxycsx3P3NmkXmuPfzSSSQu9hWMxo3hhhtM9O+6C77/3kbot21rDchffgnbQmcnBg+2zpj77ttlk4dfOonExb6CUqMGXHwxfPEFPPkkNGhgY3latoSrr7abgJMGNGwIAwfCI4/AmjU7bcrPh+++KzGNjuPEjIt9BadyZTj1VBus+d//whFHwN//bvlXzj0XPv44bAsdhg+3R65HHtnp40j4pWdBdRKBi32WIGIz4z3zDPzvfxa18+ST0L69DdTykbkh0rWr9bTfc89O0xZ6+KWTSFzss5D8fNOVJUvg5pth/nwT/Pbt4aGHLK++k2KGD7e78Guvbf8o0rJ3sXcSgYt9FlO/vg3GWrQIJkyw1v/gwebiuflmG67vpIhTT4VGjXYKw6xXz/4j76R1EoGLvUO1anDOOTBvnrlzOnSAv/7VOnOHD/eWZUrIzTXf2gsvwOLF2z/28EsnUcQt9iKySEQ+FpG5IjI7EUY54SBimTWnT7eO29NOg3HjbGR/v342sv/zz923nzQuvNBe779/+0cefukkikS17HuqakdV7Zqg/Tkhc8ABlnRt8WIL1fzwQxg2zOL1mze3LL3jx1ukiIt/gmjZEvr3t+RoGzcCJvaLF1vyO8eJB3fjOCXStCnceKN15v7vf/DAAzbZ0muvwfnnm5shLw8GDYKHH7bBXE4cDB9unSVPPAHY+d22bSfPjuOUi0SIvQKviMgcERmSgP05aYiIpWQYMgQef9wGZX36qUX1dOsGU6ea4O+5pwnU+efDv//tg7fKzFFH7RjujIdfOomjcgL2caiqLhORxsAMEVmoqm9GFwhuAkMAWrZsmYBDOmEjAvvtZ8vw4db6/OQTeOMNW55+2tw8YFMr9uxpy/HHQ61a4dqe1ojYCb34Ynj/fVq3PhBwsXfiJ+6WvaouC15XAM8CBxZRpvx5v52MoFIli9O/9FKYMgV+/BHmzLGZtvLzbWat006DJk1s4pUZMzw5W7GcfbbNZnXvvTRpYqkvvJPWiZe4xF5EaohIrcg6cCywa/o+J+vIybF5cy+/3Fw8P/1k6RrOOQdefNHm7cjLszh/z79fiNq17URNmoT8uNLDL52EEG/LvgnwXxGZB7wPvKiq0+M3y6loVK5s6RrGjDE/fiRVw223mYu6e3fb9vPPYVuaJlx0kYXgjB/v4ZdOQohL7FX1a1XtECz7q+rNiTLMqbjk5tqA0RdfhKVLzdXz66+mb02b2rapU2Hr1rAtDZH99rPO2jFj2GevrXz9tbu9nPjw0EsnVJo2NVfPvHk7YvlnzoQTToBmzWzb/PlhWxkSw4fDt99y5C9T2bzZboyOU15c7J20QAQ6dYI77rBpWadMMbfP3Xdb+obIthUrwrY0hfTrB82b0+19C8N8772Q7XEyGhd7J+2oWtUGkj7zjE3ecffd1uF72WXW2r/ggrAtTBGVK8OwYdSf8yoFrRdyxRU+05hTflzsnbSmYUObYWv2bIvjv+yyHal/s4Lzz4eqVXmg430sXgzXXx+2QU6m4mLvZAz772/RO3/5S9iWpJDGjeF3v6PZKxP4w9lr+ec/rX/DccqKi73jpDuXXALr1/PPJaeye72NXHihR+Y4ZcfF3nHSnW7dYPx4qsycwaw9TmLurI2MHRu2UU6m4WLvOJnAuefCgw+yx/zp/KfBKVx7xSZPMueUCRd7x8kUzjsPHniAg1ZNY8IvA/jTxT5ZsBM7LvZOViEiuSLyvojME5FPRWSX+BYRGSQiK4PZ1+aKyPlh2FokQ4bAmDEUbJvK757+HS8957OaOLHhYu9kG5uAo1S1A9AR6C0i3Yso90Qw+1pHVR2XWhNLYehQttx5L/15nkoDT+OX1VvCtsjJAFzsnaxCjfXB2yrBknETK1a55CK+vPRujtswha8POh22uOA7JeNi72QdIpIjInOBFcAMVZ1VRLFTRGS+iEwWkRYpNjEm8u/4A48fdAft/vcMawrOcMF3SsTF3sk6VPU3Ve0INAcOFJEDChV5AchT1fbADODhovYjIkNEZLaIzF65cmVyjS6G46ZdyjU1/kmdGZPRM8/K8lShTkm42DtZi6quBt4Aehf6fJWqRkJdxgFdivl+6DOw1a8Pbe6/jD9xO/LUk/D737vgO0XiYu9kFSLSSETqBuvVgWOAhYXK7B71th+wIHUWlp0zz4S5vf7Etbm3wqRJNsuVD7F1CpGICccdJ5PYHXhYRHKwxs6TqjpVRG4AZqvq88AlItIP2Ar8BAwKzdoYEIH77oP27Ueyb7vfGPjvqyxN6EMP2avj4GLvZBmqOh/oVMTn10atXwlcmUq74mWffeDqq+GMa6+ky9nb2OeRv9os8OPHu+A7gLtxHKfCMHKkzefb+62r2fzX6+Hhhy35/7ZtYZvmpAEu9o5TQahWDR54AL75Bq7bei1cd525coYMccF33I3jOBWJww+HwYNtEvcz5lxHu99+g5tuMpfO/ffbq5OVuNg7TgXjttvg+efhwqHCf9+6gUrbtsHf/ma++/vusx5dJ+vw27zjVDAaNIB//APefRceHCfWsr/iCmvZH388fPBB2CY6IeBi7zgVkN//Hnr2NI3/YbnA3/8O//qXCf2BB8IJJ9jEvk7W4GLvOBUQEWvIb9hgk7QjAiNGWO/tzTfDO+/YDFgu+lmDi73jVFAisfeTJsHLLwcf1q4NV121Q/TffttEv18/mDMnVHud5JIeYr9mDVx0ESxdGrYljlOhuOIKaNMGhg2DX3+N2hAR/UWLzKf/3/9C164u+hWY9BD7lSttAMjgwaAZl1rccdKW6Nj7m24qokDt2tb8d9Gv8KSH2OfnW2DwjBkwZkzY1jhOheKII2DQILj9dvj442IKRUT/m2/gxhvhrbdM9Pv3hw8/TKW5TpJID7EHGDoUjjsO/vxn+OKLsK1xnArF7bdDvXpw7LGlNNjr1IG//tVa+jfeCG++CV26uOhXANJH7EUsaVPVqp6i1XESTMOG8MYb5tY5/HAbdFUi0aJ/ww07RP/EE61T19MvZBzpI/YAzZrBvffaaJDbbw/bGsepUOy/P7z3nr2eeCLceWcMXWR16sA11+wQ/f/8Bw49FJo2hbPPtlCfn35KhflOnKSX2AMMHAgDBsC118L8+WFb4zgViqZNYeZME/sRI+CSS2Kc2Cpa9CdONH/QtGl2vTZqBIcdZgO35s3zIIs0JSFiH0zg/JGITE3AzqyTtn59Gwa4aVPp33EcJ2Z22w2eegouvxzuuceEf/36GL9cpw6ccQY89hgsX25P4VddZXGdV10FHTtCixaWWnnKFFi3Lqm/xYmdRLXsLyWRU7c1bAjjxlnL/vrrE7Zbx3GMnBwLgLvvPnjpJWuYL1tWjp10724duXPmwHffwf/9Hxx8MDz5JJx0kiXqOfpo+Oc/YeFCb/WHSNxiLyLNgQJsYubE0bcvnHce3HqrDe12HCfhDBsGU6fCl1/CQQeZF6bc7L47nHuuPTb8+KP1CI8YAT/8YI8R++5rYdYXX2wH/f57F/8UIhrnyRaRycDfgVrAn1S1bxFlhgBDAFq2bNll8eLFse187Vpo3x6qVIG5c6FGjbhsdSo+IjJHVbum+rhdu3bV2RmcY2bePCgosMHsTzwBffok+ACLF5uPf9o0eO01S9oD9hTfrp1d55Flv/3M1+RsJxH1Oi6xF5G+QB9VvUhEjqQYsY+mzBfFf/5j6fuGDbNIHccpARf78rNsmeVFmzcP7r7bMpgkhY0bYdYsc9POn28jvT7+eEc+h0qV7Akg+gbQvj3suWfWTr6SiHod7+QlPYB+ItIHyAVqi8hjqnpWnPvdwRFH2KPgv/5lAzuOPTZhu3YcZwfNmlk4/cCBMHy4uXZuvz0J85Xn5tp1fcQROz7btg2+/nrHDWD+fHuaf/rpHa6emjV3fgpo1w5atoQmTWyfTonE7cbZvqNktezBHvm6dDG3zscf21BAxykCb9nHz2+/WVrku++29tXEiSF6UNevh08/3fkmMH8+rF69c7natU30Gze216KWyLaaNTNutq50aNmnhurV4ZFHrOf/kkvg0UfDtshxKiw5OXDXXeZJuewya4C/8IL1v6acmjWt5/igg3Z8pmo+p48/tgig5ct3XhYsMPfvqlVF77N69Z1vAvXrQ61auy41axb9ea1aULkM0rlli7muNmzYsUS/j14/7DBzVyWBhIm9qs4EZiZqf7vQtasN377+egsMPuWUpB3KcRxrV7VqBaefbu2sF1+EAw4I2yqsVd68uS0lsWWLZdSNvhGsWLHz+0WL4KOPbDzAunWxp2nJzd1Z/KtVszFBRQl6WVK/PPFE+ot9Srj6agvZuvBCG7LdpEnYFjlOheaEE8yPf8IJ0KOHRVVmTLdZlSqwxx62xIKqCXRE+CPL+vW7flZ42bTJbgC5ufbkUL36zuuF3xe3nsTHp8wS+ypVzJ3TubON0HvuuYzzvTnhIiK5wJtANaz+T1bV6wqVqQY8AnQBVgGnqeqiFJuaNnTpYsEzBQUWknnnnRapU+EuPZEdotu4cdjWJJzMi2Pabz/LwfHCCzBhQtjWOJnHJuAoVe0AdAR6i0j3QmXOA35W1XzgX8CtKbYx7WjRwuY1OfZY+MMfLBr688/DtsopC5kn9gCXXmq9RpdeaoM1HCdG1IhkgqkSLIVD0voDDwfrk4FeIhWuHVtmatc2L+rYsRaL3769daF5+qrMIDPFvlIla9Wr2hQ8nlvbKQNB4r65wApghqrOKlSkGbAEQFW3AmuABqm1Mj2pVMk8qAsWwMknw6hRlvvszTfDtswpjcwUe4C8PLjjDsvXevfdYVvjZBCq+puqdgSaAweKSLliTERkiIjMFpHZK1euTKyRaU7TpvD445ZEbeNGe9A+/3xPbZ/OZK7Yg01Q3rcv/OUvllHPccqAqq4G3gB6F9q0DGgBICKVgTpYR23h749V1a6q2rVRo0bJNjct6d0bPvkERo60h+22bW0Qluc3Sz8yW+xF4MEHbXjf2WfHOAuDk82ISCMRqRusVweOAQq3FJ4HzgnWBwCva6KGmldAatSw5LRz5lhc/lln2U3gq6/CtsyJJrPFHux58v774YMPLErHcUpmd+ANEZkPfID57KeKyA0i0i8oMx5oICJfAn8E/hKSrRlFhw6Wjfzuu21OkwMOgFtusbFNTvgkLDdOrCQth8iZZ9qECe++a6NtnazEc+OkB8uW2QjcZ54x0R871uY0ccpHIup15rfsI9xzj42oPeIIuO02b044Tog0a2YJK597znKW9ehhA7HWrAnbsuyl4oh9vXrWqj/mGLjiChtl6zNcOU6o9OsHn31mrfwHHrDJqiZP9g7cMKg4Yg82zG/KFFvWrLHmxJAhHg/mOCFSq5ZFSc+aZV1sp55quXbmzw/bsuyiYol9hP79rTlx+eU2AXLbtpYW2ZsTjhMaXbvC++/DP/5hg7A6dLAEtt7VkRoqptiD5aIePdriwfbay0Izjz7aE3o4TohUrgx//KNlObn+ehP9bt3g+OPh7bfDtq5iU3HFPkIkHmzMGBP+9u3huuts2J/jOKFQrx5ce62lk7/lFrs0Dz3UEqy9/ro/hCeDii/2YAk9hg61Vv2AAXDDDTZ/5auvhm2Z42Q1tWtbPMU339g0059/Dr16mfC/9JKLfiLJDrGP0KSJjeWeMcPeH3OMxecvXx6uXY6T5dSoASNG2Jzj990HS5da7vxu3SzewnMdxk92iX2Eo4+2+Suvu87iwNq0sVG4XqMcJ1Ryc2HYMPjiCxg/3mL0TzrJMms+8UTZZvhzdiY7xR6sVo0aZfFfXbpYDevRwxJ1O44TKlWrWp7DhQvhsccs7dXpp8P++9tkdZ4Gq+xkr9hHaNPGfPePPmqZm7p0geHDbVoeb0Y4TqhUrmye1k8+sflvc3PhnHNgn30sB+L69aXvwzFc7MGyZ551ljUjzjvPatFhh9kIkHPPNafhL7+EbaXjZC2VKllsxUcfwfPPQ8OGNl6yQQPzyo4ebTcE79AtHhf7aOrXtzHdP/5oSdWOO86E/qSTrHadcILdCH74IWxLHScrEbHLcNYs+M9/LA3D8uXw5z9bgF2LFjaJyuTJ5u93dlBxsl4miy1bzKXz3HO2LFpkNe6ggyzxR//+lvDDpyhNCzzrZXaydCm8/DJMn27BdmvWQE4OdO9uufV797Z0WZUytHmbiHrtYl8WVO1ZMSL8kd/RurWJfv/+cMgh5mh0QsHF3tm61Vr+06fbEvlbGja0h/XeveHYY6Fx43DtLAsu9mGzbBm88IIJ/+uvw+bN5kQsKLBnzW7doGVLb/WnEBd7pzArVlhrf/p0a/1Hpgvu0sWE/6ij7FKtVStcO0vCxT6dWLfOatJzz8GLL8LPP9vntWubM7FdO0vVEFmvUydceysoLvZOSWzbZp28kVb/u+9a0J2IhXV2724e2u7dzTubkxO2xYaLfbqyZYs9O86fb8vHH9tr9MwNLVvuLP7t21s8WZUq4dldAXCxd8rC6tXw3nvm9om8RtppNWvCgQea+EeWpk3DsTMR9dqdy8mgShWbgy16HjZV60WKiH/kBjB9+o4RIlWrWnMi+imgdWto3hyqVw/ntzhOBaZu3R0duGCX6Rdf7Cz+t9++4xLdc8+dW/+dOlnsfybgLfuw2bzZ4vsj4h95XbZs53INGpjoF7W0aGHzwNWsGc5vSCO8Ze8kmg0b4MMPd34CWLLEtlWpYqkcunWD/fazttq++9oTQCK76rxlXxGoWtVa8e3b21DBCD/9ZJE/ixbZE0H08v77O3qZoqlbt+ibQZMm1ndQp4691q5tvVFVq6bsZzpOplK9umVS6dFjx2fffWfCHxH/Rx+1brsIdeqY6Ldtu+MGsO++0KpVeP0A3rLPVDZutNZ/4RtBZFmypPRsnrm5O8S/tKVmTav1ubmlL9Wq2Y2krE0bVXte3rzZ+j22bNmxHv1ZjRqw995F7sJb9k4YqNoNYMGCXZfoy7BaNeuai74B7LuvfVaSOyj0lr2I5AJvAtWCfU1W1evi2acTI7m55s9v3br4Mps3Ww1cscKaHWvXlr58++2O9TVrTFzjsbHwTWDbtuLFPNbsVr17W7Jzx0kTRMyT2qyZpW+I5uefzVMbfQOYPdty/UTa2pUqWav/rrsstXMyiNeNswk4SlXXi0gV4L8i8pKqvpcA25x4qVoV8vJsKS+bNpnwr1tnTxPFLZs2lbw9suTkmKOzShWzL/o1lvWqVWH33RN1hhwn6dSrt2u8BlhfwP/+t/ONIJkDveISezUfUCTvXJVg8VREFYlq1aBRI1scx0kY1avbrKkdOqTmeHFnihCRHBGZC6wAZqjqrPjNcpzkICItROQNEflMRD4VkUuLKHOkiKwRkbnBcm0YtjpOIok7GkdVfwM6ikhd4FkROUBVP4kuIyJDgCEALVu2jPeQjhMPW4HLVfVDEakFzBGRGar6WaFyb6lq3xDsc5ykkLAccKq6GngD6F3EtrGq2lVVuzZyd4ATIqr6vap+GKyvAxYAzcK1ynGST1xiLyKNghY9IlIdOAZYmAjDHCfZiEge0AkoyvV4sIjME5GXRGT/lBrmOEkgXjfO7sDDIpKD3TieVNWp8ZvlOMlFRGoCTwMjVHVtoc0fAnsGUWZ9gCnALoH97p50Mol4o3HmYy0jx8kYgjDhp4GJqvpM4e3R4q+q00TkPhFpqKo/Fio3FhgLNqgqyWY7Tlxk6LwtjlM+RESA8cACVf1nMWWaBuUQkQOx62RV6qx0nMTjuXGcbKMH8Hvg4yBkGOAqoCWAqt4PDACGichWYANwuqY6r4jjJJiU58YRkZXA4iQeoiHwY6mlkk+62AHZZcueqprykK8U1GtIn/8xXeyA9LEl7et1ysU+2YjI7DASYaWrHeC2VBTS5dylix2QPrakix0l4T57x3GcLMDF3nEcJwuoiGI/NmwDAtLFDnBbKgrpcu7SxQ5IH1vSxY5iqXA+e8dxHGdXKmLL3nEcxylEhRD7WNLWhmBTjoh8JCKhpo8QkboiMllEForIAhE5uPRvJcWOy4L/5hMReTyY5cwphXSr216vi7QlI+p2hRB7dqSt3Q/oDgwXkf1CtulSLKNi2NwJTFfVtkAHQrBJRJoBlwBdVfUAIAc4PdV2ZCjpVre9XkeRSXW7Qoh9uqWtFZHmQAEwLiwbAjvqAIdj6QFQ1c1BKuowqAxUF5HKwG7AdyHZkVGkU932el0sGVG3K4TYR1NK2tpUcQcwEtgWog0ArYCVwEPBo/c4EamRaiNUdRkwGvgW+B5Yo6qvpNqOTCcN6rbX60JkUt2uUGJfStraVNnQF1ihqnPCOH4hKgOdgTGq2gn4BfhLqo0QkXpAf+wi3QOoISJnpdqOTCbsuu31umgyqW5XGLEvLW1tCukB9BORRcAk4CgReSwkW5YCS6PmBZ6MXSSp5mjgG1VdqapbgGeAQ0KwIyNJk7rt9bpoMqZuVwixjyVtbapQ1StVtbmq5mEdNa+raih3elX9AVgiIm2Cj3oBhedaTQXfAt1FZLfgv+pFenTypT3pUre9XhdLxtTtipLiuMi0tao6LUSb0oWLgYkiUhX4Gjg31Qao6iwRmYzNALUV+IgMGHGYJnjdLprQ6zVkVt32EbSO4zhZQIVw4ziO4zgl42LvOI6TBbjYO47jZAEu9o7jOFmAi73jOE4W4GLvOI6TBbjYO47jZAEu9o7jOFnA/wP3YwxjMu+OVQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3vXmASBYf-k"
      },
      "source": [
        "print(' '.join(val[1].Text))\n",
        "translate(model, ' '.join(val[1].Text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvGQjm-kg31r"
      },
      "source": [
        "test_loss = []\n",
        "for item in val:\n",
        "    if translate(model, item.Text) == item.SQL:\n",
        "        test_loss.append(1)\n",
        "    else:\n",
        "        test_loss.append(0)\n",
        "\n",
        "print(test_loss.count(1)/len(test_loss) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}